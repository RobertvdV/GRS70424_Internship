{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import glob\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clean_paragraphs(input_dict):\n",
    "\n",
    "    # Create a new dictionary to store the cleaned-up values\n",
    "    output_dict = {}\n",
    "    \n",
    "    # Loop through the keys and values of the input dictionary\n",
    "    for key, value in input_dict.items():\n",
    "        # Convert the list of values to a set to remove duplicates\n",
    "        unique_values = set(value)\n",
    "        \n",
    "        # Join the sentences together into a single string\n",
    "        combined_string = ' '.join(unique_values)\n",
    "        \n",
    "        # Add the cleaned-up string to the output dictionary\n",
    "        output_dict[key] = combined_string\n",
    "    \n",
    "    # Return the cleaned-up dictionary\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../../../data/surveys/responses/\"\n",
    "response_list = glob.glob(F\"{folder}*\")\n",
    "\n",
    "folder = \"../../../data/surveys/surveys/\"\n",
    "survey_list = [F\"{folder}{lst[59:]}\" for lst in response_list]\n",
    "\n",
    "df_survey = pd.read_csv(survey_list[0], sep='\\t')\n",
    "df_survey.rename(columns={ df_survey.columns[0]: \"Index\" }, inplace = True)\n",
    "df_response = pd.read_csv(response_list[0], header=None).iloc[: , 1:].T\n",
    "df_response.rename(columns={ df_response.columns[0]: \"Sentence\", \n",
    "                            df_response.columns[1]: \"Result\" }, \n",
    "                            inplace = True)\n",
    "\n",
    "\n",
    "# Surveys\n",
    "df_surveys = pd.concat((pd.read_csv(f, sep='\\t') for f in survey_list), ignore_index=True)\n",
    "df_surveys.rename(columns={ df_surveys.columns[0]: \"Index\" }, inplace = True)\n",
    "\n",
    "# Response\n",
    "df_responses = pd.concat((pd.read_csv(f, header=None).iloc[: , 1:].T for f in response_list))\n",
    "df_responses.rename(columns={ df_responses.columns[0]: \"Sentence\", \n",
    "                            df_responses.columns[1]: \"Result\" }, \n",
    "                            inplace = True)\n",
    "# Melt\n",
    "df_melt = pd.melt(df_surveys, id_vars=[\"Species\",\n",
    "                                       \"Main Trait\",\n",
    "                                       \"SIM\",\n",
    "                                       \"Dataset\"],\n",
    "                             value_vars=[\"1\", \"2\", \"3\", \"4\", \"5\",],\n",
    "                             value_name=\"Sentence\"\n",
    "                \n",
    ")\n",
    "\n",
    "df_melt = df_melt.dropna()\n",
    "\n",
    "# Drop duplicates in each dataframe\n",
    "df_responses = df_responses.drop_duplicates()\n",
    "df_melt = df_melt.drop_duplicates()\n",
    "\n",
    "# Merge the dataframes based on the 'Sentence' column\n",
    "df = pd.merge(df_melt, df_responses, on='Sentence')\n",
    "df = df.drop(columns=[\"variable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_folder = \"../../../data/OpenAI/DescriptionSnippets/Paragraphs/\"\n",
    "sentence_folder = \"../../../data/OpenAI/DescriptionSnippets/Sentences/\"\n",
    "\n",
    "caribbean_jsons_paras = glob.glob(F\"{paragraph_folder}c*\")\n",
    "caribbean_jsons_sents = glob.glob(F\"{sentence_folder}c*\")\n",
    "\n",
    "caribbean_jsons_paras.sort()\n",
    "caribbean_jsons_sents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = caribbean_jsons_paras[0]\n",
    "with open(json_file, 'r') as f:\n",
    "    caribbean_species_paragraph = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Amyris ignea': 'In small scales, some families can show distinct distribution patterns, as that found for Lecythidaceae in French Guyana [32]. Mol. Cell. Opin. Microb. Front. 4 Altmetric Hop flowers are densely covered by glandular trichomes, specialized structures that secrete secondary metabolites into epidermal outgrowths3.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_clean_paragraphs(caribbean_species_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
