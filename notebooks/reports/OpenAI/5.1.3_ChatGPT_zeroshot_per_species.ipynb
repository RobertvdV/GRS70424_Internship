{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "from dotenv import load_dotenv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai.api_key = os.environ['OPENAI_API']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_present_traits(species, df):\n",
    "\n",
    "    s = df.loc[species]\n",
    "    GT_traits = list(s.where(s == 1).dropna().index)\n",
    "    empty_traits = [F\"{Entity}:\" for (Entity, Value) in GT_traits]\n",
    "\n",
    "    return GT_traits, empty_traits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trait Dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_traits = \"../../../data/OpenAI/Traits/\"\n",
    "\n",
    "with open(F\"{folder_traits}Andrei.json\", 'r') as f:\n",
    "  caribbean_traits_dict = json.load(f)\n",
    "\n",
    "with open(F\"{folder_traits}Andrei.json\", 'r') as f:\n",
    "  caribbean_traits_dict = json.load(f)\n",
    "\n",
    "with open(F\"{folder_traits}Andrei.json\", 'r') as f:\n",
    "  caribbean_traits_dict = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../../../data/OpenAI/DataFrames/\"\n",
    "\n",
    "file = \"DF_Andrei.csv\"\n",
    "df_Andrei = pd.read_csv(F\"{root}{file}\", header=[0, 1], index_col=0)\\\n",
    "    .rename_axis('Species', axis='index')\n",
    "df_Andrei_species = list(df_Andrei.index)\n",
    "\n",
    "\n",
    "file = \"DF_Daniel.csv\"\n",
    "df_Daniel = pd.read_csv(F\"{root}{file}\", header=[0, 1], index_col=0)\\\n",
    "    .rename_axis('Species', axis='index')\\\n",
    "    .dropna()\n",
    "df_Daniel_species = list(df_Daniel.index)\n",
    "\n",
    "file = \"DF_Pierre.csv\"\n",
    "df_Pierre = pd.read_csv(F\"{root}{file}\", header=[0, 1], index_col=0)\\\n",
    "    .rename_axis('Species', axis='index')\n",
    "df_Pierre_species = list(df_Pierre.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_lst = df_Andrei.index\n",
    "traits = list(caribbean_traits_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    }
   ],
   "source": [
    "# Define the path to the directory where the prompts and results will be saved\n",
    "folder_prompts = \"../../../data/OpenAI/PromptsResults/ZeroShot/\"\n",
    "\n",
    "# Loop over species\n",
    "for idx, species in (pbar := tqdm(enumerate(species_lst[0:5]), leave=False, position=0)):\n",
    "    pbar.set_description(f\"{idx}: {species}\")\n",
    "   \n",
    "    # Replace spaces in the species name with underscores\n",
    "    file_name = species.replace(' ', '_')\n",
    "\n",
    "    # Create the question and options for the ChatGPT prompt\n",
    "    question = F\"Can you create semantic triples for the following traits {traits}, for the species '{species}' and return the answer as a list of of tuples for easy parsing?\"\n",
    "    user_content = F\"{question}\"\n",
    "\n",
    "    # Check if file is already there (OpenAI Outage)\n",
    "    if os.path.exists(F\"{folder_prompts}{file_name}.json\"):\n",
    "        continue\n",
    "\n",
    "    # # Create the messages to send to the ChatGPT API\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "        ]\n",
    "    # Call the ChatGPT API to generate a completion for the prompt\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = messages,\n",
    "    )\n",
    "\n",
    "    # Lower pressure on API?\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Save the completion to a JSON file with the file name in the directory\n",
    "    with open(F\"{folder_prompts}{file_name}.json\", 'w') as fp:\n",
    "        json.dump(completion, fp)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
