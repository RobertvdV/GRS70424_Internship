{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "import collections\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines(d: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Removes newline characters from string values in a dictionary, and converts any 'None of the above' values to a list\n",
    "    with a single element 'None of the above'. Also strips square brackets from values that are lists and splits them\n",
    "    into separate string elements.\n",
    "    Args:\n",
    "        d: The input dictionary to process.\n",
    "\n",
    "    Returns:\n",
    "        The processed dictionary with newlines removed and 'None of the above' values as lists.\n",
    "\n",
    "    \"\"\"\n",
    "    for k, v in d.items():\n",
    "        d[k] = v.replace('\\n', '').strip()\n",
    "        if d[k] == 'None of the above.':\n",
    "            d[k] = ['None of the above']\n",
    "        else:\n",
    "            d[k] = [val.strip() for val in d[k].strip('[]').split(',')]\n",
    "    return d\n",
    "\n",
    "\n",
    "def strip_quotes(d: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Removes quotes around string values in a dictionary, and converts lists of quoted string values into lists of\n",
    "    unquoted string values.\n",
    "    Args:\n",
    "        d: The input dictionary to process.\n",
    "\n",
    "    Returns:\n",
    "        The processed dictionary with quotes removed from string values and lists of unquoted string values.\n",
    "    \"\"\"\n",
    "    new_dict = {}\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, list):\n",
    "            new_list = []\n",
    "            for item in v:\n",
    "                if isinstance(item, str):\n",
    "                    new_list.append(item.strip().strip(\"'\"))\n",
    "                else:\n",
    "                    new_list.append(item)\n",
    "            new_dict[k] = new_list\n",
    "        else:\n",
    "            new_dict[k] = v.strip().strip(\"'\")\n",
    "    return new_dict\n",
    "\n",
    "def extract_name_and_file(path):\n",
    "    filename = os.path.basename(path)\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    species_name = path.split('/')[-2]\n",
    "    return species_name, name\n",
    "\n",
    "def split_on_capitals(string):\n",
    "    # Split the string at every capital letter\n",
    "    split_string = re.findall('[A-Z][^A-Z]*', string)\n",
    "    # Join the split string with spaces\n",
    "    new_string = ' '.join(split_string)\n",
    "    \n",
    "    return new_string\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove slashes and spaces around them\n",
    "    text = re.sub(r'\\s*/\\s*', '', text)\n",
    "    # Remove any remaining spaces\n",
    "    text = re.sub(r'\\s+', '', text)\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_traits = \"../../../data/OpenAI/Traits/\"\n",
    "\n",
    "with open(F\"{folder_traits}Andrei.json\", 'r') as f:\n",
    "  caribbean_traits_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    }
   ],
   "source": [
    "# Define the path where the prompt results are stored\n",
    "folder_prompts = \"../../../data/OpenAI/PromptsResults/\"\n",
    "\n",
    "# Get a list of all folders in the path\n",
    "species_folders = glob.glob(F\"{folder_prompts}*\")\n",
    "\n",
    "# Create a defaultdict to store the prompt results for each species\n",
    "prompt_results_dict = collections.defaultdict(dict)\n",
    "\n",
    "# Loop through each species folder\n",
    "for idx, species_folder in enumerate(species_folders):\n",
    "    # Extract the species name from the folder path\n",
    "    species_name = species_folder[36:60].replace('_', ' ')\n",
    "    \n",
    "    # Get a list of all JSON files in the folder\n",
    "    json_list = glob.glob(F\"{species_folder}/*\")\n",
    "\n",
    "    # Loop through each JSON file\n",
    "    for json_file in (pbar := tqdm(json_list, leave=False, position=0)):\n",
    "        # Update the progress bar description\n",
    "        pbar.set_description(f\"{idx}: {species_name}\")\n",
    "\n",
    "        # Create an empty dictionary to store the trait results\n",
    "        trait_dict = {}\n",
    "\n",
    "        # Extract the trait name and file name from the JSON file path\n",
    "        _, trait = extract_name_and_file(json_file)\n",
    "        # Clean up the trait name by splitting on capital letters\n",
    "        trait = split_on_capitals(trait)\n",
    "\n",
    "        # Read in the JSON file\n",
    "        with open(json_file, 'r') as f:\n",
    "            prompt_result = json.load(f)\n",
    "\n",
    "        # Extract the prompt result for the trait and add it to the trait dictionary\n",
    "        trait_dict[trait] = prompt_result['choices'][0]['message']['content']\n",
    "        # Clean up the trait dictionary by removing newlines and quotes\n",
    "        trait_dict = remove_newlines(trait_dict)\n",
    "        trait_dict = strip_quotes(trait_dict)\n",
    "\n",
    "        # print('asda, ' , trait_dict)\n",
    "\n",
    "        # Add the trait dictionary to the list of prompt results for the species\n",
    "        trait_name = list(trait_dict.keys())[0]\n",
    "        trait_name_cap = trait_name.capitalize()\n",
    "        # print(trait_dict[trait_name])\n",
    "        prompt_results_dict[species_name][trait_name_cap] = trait_dict[trait_name] # Contains a list\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe with GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../../../data/OpenAI/DataFrames/\"\n",
    "\n",
    "file = \"DF_Andrei.csv\"\n",
    "df_Andrei = pd.read_csv(F\"{root}{file}\", header=[0, 1], index_col=0)\\\n",
    "    .rename_axis('Species', axis='index')\n",
    "df_Andrei = df_Andrei.rename(columns={'Thorns/spines': 'Thorns spines', \n",
    "                                      'Sepals / calyx shape': 'Sepals calyx shape', \n",
    "                                      'Petals / corolla shape': 'Petals corolla shape',\n",
    "                                      'Petals / corolla number': 'Petals corolla number',\n",
    "                                      'Petals / corolla colour': 'Petals corolla colour',\n",
    "                                      'Sepals / calyx numer': 'Sepals calyx numer',})\n",
    "df_Andrei_species = list(df_Andrei.index)\n",
    "\n",
    "\n",
    "file = \"DF_Daniel.csv\"\n",
    "df_Daniel = pd.read_csv(F\"{root}{file}\", header=[0, 1], index_col=0)\\\n",
    "    .rename_axis('Species', axis='index')\\\n",
    "    .dropna()\n",
    "df_Daniel_species = list(df_Daniel.index)\n",
    "\n",
    "file = \"DF_Pierre.csv\"\n",
    "df_Pierre = pd.read_csv(F\"{root}{file}\", header=[0, 1], index_col=0)\\\n",
    "    .rename_axis('Species', axis='index')\n",
    "df_Pierre_species = list(df_Pierre.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_GT_traits(species, df):\n",
    "\n",
    "    s = df.loc[species]\n",
    "    GT_traits = list(s.where(s == 1).dropna().index)\n",
    "\n",
    "    return GT_traits\n",
    "\n",
    "def extract_ALL_traits(species, df):\n",
    "\n",
    "    s = df.loc[species]\n",
    "    traits = list(s.index)\n",
    "\n",
    "    # Create a dict\n",
    "    result = {}\n",
    "    for key, value in traits:\n",
    "        if key in result:\n",
    "            result[key].append(value)\n",
    "        else:\n",
    "            result[key] = [value]\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caribbean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame with a multi-level index based on the columns of another DataFrame\n",
    "df_Andrei_ChatGPT = pd.DataFrame(index=pd.MultiIndex.from_tuples(df_Andrei.columns)).T\n",
    "\n",
    "# Loop through each species in a dictionary of ground truth traits\n",
    "for species in prompt_results_dict.keys():\n",
    "\n",
    "    # Extract the ground truth traits for the current species from a DataFrame\n",
    "    ALL_traits = extract_ALL_traits(species, df_Andrei)\n",
    "\n",
    "    # Loop through each trait and its corresponding value in the ground truth traits\n",
    "    for trait, value in ALL_traits.items():\n",
    "\n",
    "        # print(trait, 'Correct')\n",
    "        ChatGPT_result = prompt_results_dict[species][trait]\n",
    "\n",
    "        # Find the correct values by finding the intersection between the ground truth values and the ChatGPT result\n",
    "        correct_values = list(set(value) & set(ChatGPT_result))\n",
    "\n",
    "        # Set a value of 1 in the DataFrame for each correct value for the current species and trait\n",
    "        for correct_value in correct_values:\n",
    "            df_Andrei_ChatGPT.loc[species, (trait, correct_value)] = 1 \n",
    "\n",
    "folder_prompt_results = \"../../../data/OpenAI/PromptsAnalysesData/\"\n",
    "\n",
    "df_Andrei_ChatGPT.to_csv(F\"{folder_prompt_results}caribbean_df_ChatGPT.csv\")\n",
    "df_Andrei.loc[df_Andrei_ChatGPT.index].to_csv(F\"{folder_prompt_results}.caribbean_df_GT.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
