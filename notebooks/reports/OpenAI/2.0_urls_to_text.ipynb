{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import requests\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_url = \"../../../data/OpenAI/Urls/\"\n",
    "\n",
    "caribbean_url_dict = pickle.load(open(F\"{folder_url}urls_caribbean.pkl\", 'rb'))\n",
    "palms_url_dict = pickle.load(open(F\"{folder_url}urls_palms.pkl\", 'rb'))\n",
    "plantnet_url_dict = pickle.load(open(F\"{folder_url}urls_plantnet.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "# caribbean_url_dict = {k: caribbean_url_dict[k][0:5] for k in list(caribbean_url_dict)[:4]}\n",
    "# palms_url_dict = {k: palms_url_dict[k][0:5] for k in list(palms_url_dict)[:4]}\n",
    "# plantnet_url_dict = {k: plantnet_url_dict[k][0:5] for k in list(plantnet_url_dict)[:4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paragraphs_from_urls(url_dict):\n",
    "\n",
    "    # Init dict\n",
    "    text_dict = collections.defaultdict(list)\n",
    "\n",
    "    # Loop over species and URLS\n",
    "    for (species, urls) in tqdm(url_dict.items(), desc=\"Species\", leave=True, position=0):\n",
    "        for url in tqdm(urls, desc=\"URL\", leave=False, position=0):\n",
    "\n",
    "            try:\n",
    "                session = requests.Session()\n",
    "                retry = Retry(total=1,\n",
    "                              connect=1, \n",
    "                              backoff_factor=0.5)\n",
    "                adapter = HTTPAdapter(max_retries=retry)\n",
    "                session.mount('http://', adapter)\n",
    "                session.mount('https://', adapter)\n",
    "                response = session.get(url, timeout=3)\n",
    "                # response = requests.get(url)\n",
    "                \n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                paragraphs = soup.find_all('p')\n",
    "                for paragraph in paragraphs:\n",
    "                    text_dict[species].append(paragraph.text)\n",
    "\n",
    "            except:\n",
    "                text_dict[species].append(\"Invalid URL\")\n",
    "\n",
    "    return text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "URL:  70%|███████   | 28/40 [00:22<00:11,  1.03it/s]/it]/usr/local/anaconda3/envs/webscraping/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "Species: 100%|██████████| 42/42 [33:14<00:00, 47.50s/it]\n"
     ]
    }
   ],
   "source": [
    "caribbean_text_dict = extract_paragraphs_from_urls(caribbean_url_dict)\n",
    "# palms_text_dict = extract_paragraphs_from_urls(palms_url_dict)\n",
    "# plantnet_text_dict = extract_paragraphs_from_urls(plantnet_url_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_text = \"../../../data/OpenAI/TextSnippets/\"\n",
    "\n",
    "with open(F\"{folder_text}paragraphs_caribbean.pkl\", 'wb') as f:\n",
    "    pickle.dump(caribbean_text_dict, f)\n",
    "\n",
    "# with open(F\"{folder_text}paragraphs_palms.pkl\", 'wb') as f:\n",
    "#     pickle.dump(palms_text_dict, f)\n",
    "\n",
    "# with open(F\"{folder_text}paragraphs_plantnet.pkl\", 'wb') as f:\n",
    "#     pickle.dump(plantnet_text_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscraping",
   "language": "python",
   "name": "webscraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "020a6b5c0ed803a704c00010560cf50a059d086f11791eecdae2eedc39704b9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
