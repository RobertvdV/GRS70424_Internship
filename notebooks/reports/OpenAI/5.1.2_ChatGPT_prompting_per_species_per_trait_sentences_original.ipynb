{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import os\n",
    "import os.path\n",
    "import json\n",
    "import pickle\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai.api_key = os.environ['OPENAI_API']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../../../data/OpenAI/DataFrames/\"\n",
    "\n",
    "file = \"DF_Andrei.csv\"\n",
    "df_Andrei = pd.read_csv(F\"{root}{file}\", header=[0, 1], index_col=0)\\\n",
    "    .rename_axis('Species', axis='index')\n",
    "df_Andrei_species = list(df_Andrei.index)\n",
    "\n",
    "\n",
    "file = \"DF_Daniel.csv\"\n",
    "df_Daniel = pd.read_csv(F\"{root}{file}\", header=[0, 1], index_col=0)\\\n",
    "    .rename_axis('Species', axis='index')\\\n",
    "    .dropna()\n",
    "df_Daniel_species = list(df_Daniel.index)\n",
    "\n",
    "file = \"DF_Pierre.csv\"\n",
    "df_Pierre = pd.read_csv(F\"{root}{file}\", header=[0, 1], index_col=0)\\\n",
    "    .rename_axis('Species', axis='index')\n",
    "df_Pierre_species = list(df_Pierre.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trait Dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_traits = \"../../../data/OpenAI/Traits/\"\n",
    "\n",
    "with open(F\"{folder_traits}Andrei.json\", 'r') as f:\n",
    "  caribbean_traits_dict = json.load(f)\n",
    "\n",
    "with open(F\"{folder_traits}Andrei.json\", 'r') as f:\n",
    "  caribbean_traits_dict = json.load(f)\n",
    "\n",
    "with open(F\"{folder_traits}Andrei.json\", 'r') as f:\n",
    "  caribbean_traits_dict = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_words_with_capital(string):\n",
    "    # remove non-alphanumeric characters\n",
    "    string = re.sub(r'[^\\w\\s/]', '', string)\n",
    "    # split the string on the slash (\"/\")\n",
    "    parts = string.split('/')\n",
    "    # combine words with capitalization for each part\n",
    "    parts = [''.join(word.capitalize() for word in part.split()) for part in parts]\n",
    "    # join the parts with an empty string\n",
    "    return ''.join(parts)\n",
    "\n",
    "def create_clean_paragraphs(input_dict):\n",
    "\n",
    "    # Create a new dictionary to store the cleaned-up values\n",
    "    output_dict = {}\n",
    "    \n",
    "    # Loop through the keys and values of the input dictionary\n",
    "    for key, value in input_dict.items():\n",
    "        # Convert the list of values to a set to remove duplicates\n",
    "        unique_values = set(value)\n",
    "        \n",
    "        # Join the sentences together into a single string\n",
    "        combined_string = ' '.join(unique_values)\n",
    "        \n",
    "        # Add the cleaned-up string to the output dictionary\n",
    "        output_dict[key] = combined_string\n",
    "    \n",
    "    # Return the cleaned-up dictionary\n",
    "    return output_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data\n",
    "#### Caribbean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_sents = \"../../../data/OpenAI/DescriptionSnippets/SentencesOriginal/\"\n",
    "\n",
    "caribbean_file = \"Sents_Caribbean.pkl\"\n",
    "caribbean_sents = pickle.load(open(F\"{folder_sents}{caribbean_file}\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "caribbean_paras = create_clean_paragraphs(caribbean_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = ['Avicennia germinans',\n",
    " 'Metopium brownei',\n",
    " 'Handroanthus billbergii',\n",
    " 'Bourreria succulenta',\n",
    " 'Bursera karsteniana',\n",
    " 'Bursera simaruba',\n",
    " 'Bursera tomentosa',\n",
    " 'Cynophalla flexuosa',\n",
    " 'Cynophalla hastata',\n",
    " 'Quadrella odoratissima',\n",
    " 'Crossopetalum rhacoma',\n",
    " 'Maytenus versluysii',\n",
    " 'Clusia rosea',\n",
    " 'Conocarpus erectus',\n",
    " 'Laguncularia racemosa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    }
   ],
   "source": [
    "# Define the path to the directory where the prompts and results will be saved\n",
    "folder_prompts = \"../../../data/OpenAI/PromptsResults/OriginalData/\"\n",
    "\n",
    "choices = [\n",
    "    1, 0, \n",
    "]\n",
    "\n",
    "# Loop over each JSON file in the list caribbean_jsons_paras\n",
    "for idx, (species, text) in enumerate(caribbean_paras.items()):\n",
    "\n",
    "    if species not in test_list:\n",
    "        continue\n",
    "    \n",
    "    # Replace spaces in the species name with underscores\n",
    "    folder_species = species.replace(' ', '_')\n",
    "\n",
    "    # Try to create a directory for the prompts for the species\n",
    "    try:\n",
    "        os.makedirs(F\"{folder_prompts}{folder_species}\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # Loop over each trait and trait options in the caribbean_traits_dict dictionary\n",
    "    for trait, trait_options in (pbar := tqdm(caribbean_traits_dict.items(), leave=False, position=0)):\n",
    "        pbar.set_description(f\"{idx}: {species}\")\n",
    "\n",
    "        # Create the question and options for the ChatGPT prompt\n",
    "        question = F\"Which of the following values correctly describe(s) the '{trait}' trait mentioned in the text? Fill in a '1', if the trait value is likely to occur based on the text, '0' if it is unlikely to occur and 'NA' if there is no information that can be used to infer the occurrence of the trait.\"\n",
    "        format = F\"\\nPlease ONLY return a Python list of tuples with ALL the options/value combinations from the list with options, like this: [({trait_options[0]}, {random.choice(choices)}), (({trait_options[1]}, {random.choice(choices)}))]\"\n",
    "        options = F\"\\nThe possible values for this trait are: {trait_options}.\"\\\n",
    "\n",
    "        user_content = F\"{question} {options} {format}\"\n",
    "        # print(user_content)\n",
    "\n",
    "        # Combine the words in the trait name with capital letters and use this as the file name\n",
    "        file_name = combine_words_with_capital(trait)\n",
    "        # Check if file is already there (OpenAI Outage)\n",
    "        if os.path.exists(F\"{folder_prompts}{folder_species}/{file_name}.json\"):\n",
    "            continue\n",
    "\n",
    "        # Create the messages to send to the ChatGPT API\n",
    "        messages = [\n",
    "            {\"role\": \"assistant\", \"content\": text},\n",
    "            {\"role\": \"user\", \"content\": user_content}\n",
    "            ]\n",
    "        # Call the ChatGPT API to generate a completion for the prompt\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model = \"gpt-3.5-turbo\",\n",
    "            messages = messages,\n",
    "        )\n",
    "\n",
    "\n",
    "        # Save the completion to a JSON file with the file name in the species directory\n",
    "        with open(F\"{folder_prompts}{folder_species}/{file_name}.json\", 'w') as fp:\n",
    "            json.dump(completion, fp)\n",
    "            \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caribbean_traits_dict\n",
    "\n",
    "trait = list(caribbean_traits_dict.keys())[22]\n",
    "trait_options = caribbean_traits_dict[trait]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trait_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = [\n",
    "    1, 0, \n",
    "]\n",
    "\n",
    "question = F\"Which of the following values correctly describe(s) the '{trait}' trait mentioned in the text? Fill in a '1', if the trait value is likely to occur based on the text, '0' if it is unlikely to occur and 'NA' if there is no information that can be used to infer the occurrence of the trait.\"\n",
    "format = F\"\\nPlease ONLY return a Python list of tuples with ALL the options/value combinations from the list with options, like this: [('{trait_options[0]}', '{random.choice(choices)}'), ('{trait_options[1]}', '{random.choice(choices)}')] or in case there is not information: [('{trait_options[0]}', 'NA'), ('{trait_options[1]}', 'NA')]\"\n",
    "options = F\"\\nThe possible values for this trait are: {trait_options}.\"\\\n",
    "\n",
    "user_content = F\"{question} {options} {format}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F\"\"\"text:\n",
    "{text}\n",
    "\"\"\")\n",
    "print(user_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the messages to send to the ChatGPT API\n",
    "messages = [\n",
    "    {\"role\": \"assistant\", \"content\": text},\n",
    "    {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "# Call the ChatGPT API to generate a completion for the prompt\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51432b8e5767c06330d9b51dfad63f9db0ea39868e37d921b9c2e277373f8d11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
