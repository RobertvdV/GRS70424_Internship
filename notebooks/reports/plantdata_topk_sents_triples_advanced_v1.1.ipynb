{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "import json\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "from itertools import groupby\n",
    "import pickle\n",
    "import re\n",
    "import matplotlib.colors as mcolors\n",
    "import warnings\n",
    "import requests\n",
    "import csv\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from functools import reduce\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = {x.name().split('.', 1)[0] for x in wn.all_synsets('n')}\n",
    "\n",
    "colors = [color[4:] for color in mcolors.TABLEAU_COLORS.keys()]\n",
    "colors.extend([color for color in mcolors.CSS4_COLORS.keys()])\n",
    "colors.extend(\n",
    "    [\n",
    "        'whitish', 'bluish', 'reddish', 'greenish', 'backish', 'greyish',\n",
    "        'backish', 'purplish', 'yellowish', 'orangish', 'brownish', 'pinkish'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../../data/external/\"\n",
    "\n",
    "# Data Pierre\n",
    "file_name = root + 'Dataset_Pierre.csv'\n",
    "df_Pierre = pd.read_csv(file_name, header=[0, 1]) \n",
    "df_Pierre = df_Pierre.iloc[: , 1:]\n",
    "df_Pierre = df_Pierre.set_index(df_Pierre['Species']['species'])\n",
    "\n",
    "# Data Andrei\n",
    "file_name = root + 'Dataset_Andrei.csv'\n",
    "df_Andrei = pd.read_csv(file_name)\n",
    "\n",
    "# Get Dummies to match DF Pierre\n",
    "df_Andrei_dummies = pd.get_dummies(df_Andrei.iloc[:, 2:])\n",
    "# Set species back\n",
    "df_Andrei_dummies = df_Andrei_dummies.set_index(df_Andrei['Species'])\n",
    "\n",
    "# Create tuple list for multi index\n",
    "Andrei_multi_index = []\n",
    "for top_index in df_Andrei.columns:\n",
    "    for sub_index in df_Andrei_dummies.columns:\n",
    "        if top_index in sub_index:\n",
    "\n",
    "            sub_index = sub_index.split('_')[-1]\n",
    "            Andrei_multi_index.append((top_index, sub_index))\n",
    "\n",
    "# Set Mutli index\n",
    "df_Andrei_dummies.columns = pd.MultiIndex.from_tuples(Andrei_multi_index)\n",
    "\n",
    "# Data Palms\n",
    "file_name = root + 'Dataset_Kissling.txt'\n",
    "df_Daniel = pd.read_csv(file_name,\n",
    "                 sep='\\t', encoding='Latin-1')\n",
    "palm_species = df_Daniel[~df_Daniel.isnull().any(axis=1)]['SpecName'].values\n",
    "df_Daniel.set_index('SpecName', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RESHAPE DATA FOR PALMS\n",
    "\n",
    "# Exclude string types\n",
    "df_Daniels_int = df_Daniel.select_dtypes(exclude=[object])\n",
    "df_Daniels_str = df_Daniel.select_dtypes(include=[object])\n",
    "# Drop numbers\n",
    "df_Daniels_semi_ints = df_Daniels_int.loc[:, df_Daniels_int.max() <= 3]\n",
    "# Merge again\n",
    "df_Daniel_edit = pd.merge(df_Daniels_str, df_Daniels_semi_ints, left_index=True, right_index=True)\n",
    "\n",
    "# Get colors as lst of lsts \n",
    "FruitColorDescription_colors_lst = []\n",
    "\n",
    "for palm_colors in df_Daniels_str['FruitColorDescription'].values:\n",
    "    if type(palm_colors) == str:\n",
    "        #print(type(colors))\n",
    "        palm_colors = re.split(r'; |to | |-', palm_colors)\n",
    "\n",
    "        #print(palm_colors)\n",
    "        FruitColorDescription_colors_lst.append([color for color in palm_colors if color in colors])\n",
    "    else:\n",
    "        FruitColorDescription_colors_lst.append([])\n",
    "\n",
    "MainFruitColors_colors_lst = []\n",
    "\n",
    "for palm_colors in df_Daniels_str['MainFruitColors'].values:\n",
    "    if type(palm_colors) == str:\n",
    "        #print(type(colors))\n",
    "        palm_colors = re.split(r'; |to | |-', palm_colors)\n",
    "\n",
    "        #print(palm_colors)\n",
    "        MainFruitColors_colors_lst.append([color for color in palm_colors if color in colors])\n",
    "    else:\n",
    "        MainFruitColors_colors_lst.append([])\n",
    "\n",
    "# Init SKlearn MLB\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Create dummies for color columns\n",
    "df_FruitColorDescription = pd.DataFrame(\n",
    "    {\n",
    "        'FruitColorDescription': FruitColorDescription_colors_lst\n",
    "    }, columns=['FruitColorDescription'])\n",
    "\n",
    "s = df_FruitColorDescription['FruitColorDescription']\n",
    "df_FruitColorDescription = pd.DataFrame(mlb.fit_transform(s),columns=mlb.classes_, index=df_Daniel.index)\n",
    "\n",
    "# Multiindex columns\n",
    "columns = [('FruitColorDescription', column) for column in df_FruitColorDescription.columns]\n",
    "df_FruitColorDescription.columns = pd.MultiIndex.from_tuples(columns)\n",
    "\n",
    "# Create dummies for color columns\n",
    "df_MainFruitColors = pd.DataFrame(\n",
    "    {\n",
    "        'MainFruitColors': MainFruitColors_colors_lst\n",
    "    }, columns=['MainFruitColors'])\n",
    "\n",
    "s = df_MainFruitColors['MainFruitColors']\n",
    "df_MainFruitColors = pd.DataFrame(mlb.fit_transform(s),columns=mlb.classes_, index=df_Daniel.index)\n",
    "\n",
    "# Multiindex columns\n",
    "columns = [('Fruit Colour', column) for column in df_MainFruitColors.columns]\n",
    "df_MainFruitColors.columns = pd.MultiIndex.from_tuples(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Daniels_str_non_color = df_Daniels_str[['UnderstoreyCanopy', 'FruitSizeCategorical', 'FruitShape', 'Conspicuousness']]\n",
    "\n",
    "# df_Daniels_str_non_color.columns = pd.MultiIndex.from_tuples(\n",
    "#     [\n",
    "#         ('Crown', 'UnderstoreyCanopy'),\n",
    "#         ('Fruit Size', 'FruitSizeCategorical'),\n",
    "#         ('Fruit Shape', 'FruitShape'),\n",
    "#         ('Conspicuousness', 'Conspicuousness'),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "df_Daniels_str_non_color_dummies = pd.get_dummies(df_Daniels_str_non_color)\n",
    "columns = []\n",
    "for column in df_Daniels_str_non_color_dummies.columns:\n",
    "    level0, level1 = column.split('_')\n",
    "    if level0 == 'UnderstoreyCanopy':\n",
    "        level0 = 'Crown'\n",
    "    elif level0 == 'FruitSizeCategorical':\n",
    "        level0 = 'Fruit Size'\n",
    "    elif level0 == 'FruitShape':\n",
    "        level0 = 'Fruit Shape'\n",
    "    elif level0 == 'Conspicuousness':\n",
    "        level0 = 'Conspicuousness'\n",
    "    columns.append((level0, level1))\n",
    "    \n",
    "df_Daniels_str_non_color_dummies.columns = pd.MultiIndex.from_tuples(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### JOIN ALL DATA\n",
    "data_frames = [df_FruitColorDescription, df_MainFruitColors, df_Daniels_str_non_color_dummies]\n",
    "df_Daniel_merged = pd.concat(data_frames, axis=1)\n",
    "# df_Daniel_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "traits_dict = {\n",
    "    'Life Form':\n",
    "    [\n",
    "        'Tree', 'Shrub', 'Bush', 'Ficus', 'Strangler', 'Liana', 'Parasitic', 'Palm', 'Herbaceous'\n",
    "    ],\n",
    "    'Trunk':\n",
    "    [\n",
    "        'Trunk', 'Straight', 'Flared', 'Foothills', 'Silt', 'Aerial'\n",
    "    ],\n",
    "    'Root':\n",
    "    [\n",
    "        'Root', 'Straight', 'Flared', 'Foothills', 'Silt', 'Aerial'\n",
    "    ],\n",
    "    'Latex':\n",
    "    [\n",
    "        'Latex'\n",
    "    ],\n",
    "    'Phyllotaxis': # Leaf Position\n",
    "    [\n",
    "        'Phyllotaxis', 'Alternate', 'Whorled', 'Whorls', 'Opposite'\n",
    "    ],\n",
    "    'Leaf Composition':\n",
    "    [\n",
    "        'Palmate', 'Pinnate', 'Entire', 'Bi-pinnate'\n",
    "    ],\n",
    "    'Crown':\n",
    "    [\n",
    "        'Crown'\n",
    "    ],\n",
    "    'Stem':\n",
    "    [\n",
    "        'Stem', 'Circular', 'Square'\n",
    "    ],\n",
    "    'Bark':\n",
    "    [\n",
    "        'Bark'\n",
    "    ],\n",
    "    'Bark Colour':\n",
    "    [\n",
    "        'Bark'\n",
    "    ],\n",
    "    'Leaf Shape':\n",
    "    [\n",
    "        'Simple', 'Bifoliate', 'Trifoliate', 'Digitized', 'Paripinnate', 'Unipinnate', 'Imperipinnate', \n",
    "        'Alternate', 'Bipinnate', 'Pinnate', 'Elliptic', 'Elongate', 'Ovate', 'Round', 'Obovate', 'Lanceolate',\n",
    "        'Kidney-shaped', 'Heart-shaped', 'Spathulate'\n",
    "    ],\n",
    "    'Petiole':\n",
    "    [\n",
    "        'Petiole', 'Sessile', 'Petiolated', 'Canaliculate', 'Glands', 'Glandular', \n",
    "     'Winged' 'Wings', 'Hairs', 'Hair', 'Translucent'\n",
    "     ],\n",
    "    'Leaf Colour':\n",
    "    [\n",
    "        'Leaf Colour', 'Leaf Color'\n",
    "    ],\n",
    "    'Leaf Blade':\n",
    "    [\n",
    "        'Leaf Blade', 'Linear', 'Lanceolate', 'Elliptical', 'Obovate', 'Obtriangular', \n",
    "        'Obtriangular', 'Asymmetrical', 'Orbicular', 'Bilobed', 'Lobed', 'Lobes', 'Lobe'\n",
    "    ],\n",
    "    'Leaf Base':\n",
    "    [\n",
    "        'Leaf Base', 'Rounded', 'Cordate', 'Glands'\n",
    "    ],\n",
    "    'Leaf Margin':\n",
    "    [\n",
    "        'Margin', 'Smooth', 'Wavy', 'Crenate', 'Toothed', 'Teeth', 'Crenate', 'Serrate'\n",
    "    ],\n",
    "    'Leaf Apex':\n",
    "    [\n",
    "        'Apex', 'Acuminate', 'Apiculate', 'Mucronate', 'Rounded', 'Emarginated'\n",
    "    ],\n",
    "    'Leaf side':\n",
    "    [\n",
    "        'Glabrous', 'Pubescent', 'Salt Crystals', 'Scales', 'Woolly', 'Powdery'\n",
    "    ],\n",
    "    'Leaf glands':\n",
    "    [\n",
    "        'Glands', 'Gland', 'Translucent'\n",
    "    ],\n",
    "    'Rachis':\n",
    "    [\n",
    "        'Rachis', 'Winged'\n",
    "    ],\n",
    "    'Vein':\n",
    "    [\n",
    "        'Vein'\n",
    "    ],\n",
    "    'Tendril':\n",
    "    [\n",
    "        'Tendril'\n",
    "    ],\n",
    "    'Spine':\n",
    "    [\n",
    "        'Spine', 'Prickle', 'Spines', 'Prickles'\n",
    "    ],\n",
    "    'Thornes':\n",
    "    [\n",
    "        'Thorn', 'Thornes'\n",
    "    ],\n",
    "    'Blade Colour':\n",
    "    [\n",
    "        'Blade'\n",
    "    ],\n",
    "    'Fruit':\n",
    "    [\n",
    "        'Drupe', 'Berry', 'Capsule', 'Pod', 'Follicle', 'Achene', 'Winged', 'Follicle',\n",
    "        'Pod', 'Nutlet', 'Fruit'\n",
    "    ],\n",
    "    'Fruit Shape':\n",
    "    [\n",
    "        'locular', 'Globose', 'Flattened', 'Elongate', 'Obovoid', 'Ovate', 'Twisted',\n",
    "        'Curved', 'Pyriform', 'Ovoid'\n",
    "    ],\n",
    "    'Fruit Colour':\n",
    "    [\n",
    "        'Fruit'\n",
    "    ],\n",
    "    'Inflorescences':\n",
    "    [\n",
    "        'Inflorescences', 'Inflorescence', 'Sessile', 'Panicle', 'Flower head', 'Cyme', 'Glomerule', \n",
    "        'Fascicle', 'Umbel', 'Corymb', 'Rootlet', 'Spike', 'Dichasium', 'Fascicle',\n",
    "        'Globose', 'Raceme', 'Fascicle', 'Umbel'\n",
    "     ],\n",
    "    'Sexuality':\n",
    "    [\n",
    "        'Sexuality', 'Axillary', 'Terminal'\n",
    "    ],\n",
    "    'Flower Colour':\n",
    "    [\n",
    "        'Flower colour', 'Flower color', 'Flower', 'Flowers'\n",
    "    ],\n",
    "    'Flower Shape':\n",
    "    [\n",
    "        'Flower shape', 'Petalled', 'Petal', 'Petals', 'Tubular', 'Apetal', 'Butterfly-shaped', 'Shaped', 'Flower', 'Flowers'\n",
    "    ],\n",
    "    'Sepal Shape':\n",
    "    [\n",
    "        'Sepal', 'Sepals', 'Connate'\n",
    "    ],\n",
    "    'Petal Shape':\n",
    "    [\n",
    "        'Petal', 'Petals', 'Tepals', 'Tepal', 'Tubular'\n",
    "    ],\n",
    "    'Aril Colour':\n",
    "    [\n",
    "        'Aril'\n",
    "    ],\n",
    "    'Seed Colour':\n",
    "    [\n",
    "        'Seed', \n",
    "    ],\n",
    "    'Conspicuousness':\n",
    "    [\n",
    "        'Conspicuousness', 'Cryptic'\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('../../data/supportive/traits_Pierre_and_Andrei.json', 'w') as f:\n",
    "    json.dump(traits_dict, f)\n",
    "with open('../../data/supportive/colour_list.json', 'w') as f:\n",
    "    json.dump(colors, f)\n",
    "\n",
    "traits_list = list(traits_dict.keys())\n",
    "traits_list += [trait.lower() for lst in list(traits_dict.values()) for trait in lst]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = list(stopwords.words('english'))\n",
    "sw.append('like')\n",
    "sw.append('color')\n",
    "sw.append('colour')\n",
    "sw.append('a')\n",
    "sw.append('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corresponding_keys(val, dictionary):\n",
    "    \"\"\"returns the corresponding key of a single value \n",
    "    assuming the values are lists.\n",
    "\n",
    "    Args:\n",
    "        val (string): string present in the dict\n",
    "        dictionary (dict): dict with lists of stings as values\n",
    "\n",
    "    Returns:\n",
    "        list: list of matching keys\n",
    "    \"\"\"\n",
    "    # Init list\n",
    "    keys = []\n",
    "    # Search the dict\n",
    "    for k, v in dictionary.items():\n",
    "        if val in v:\n",
    "            keys.append(k)\n",
    "    return keys\n",
    "    \n",
    "def jaccard_similarity(A, B):\n",
    "    \"\"\"Calculates the Jaccard similarity two sets.\n",
    "\n",
    "    Args:\n",
    "        A (Set): Set A\n",
    "        B (Set): Set B\n",
    "\n",
    "    Returns:\n",
    "        Integer: 0.00 - 1.00\n",
    "    \"\"\"\n",
    "\n",
    "    # Create sets just in case\n",
    "    A = set(A)\n",
    "    B = set(B)\n",
    "    \n",
    "    # Get intersection of two sets\n",
    "    nominator = A.intersection(B)\n",
    "\n",
    "    # Find union of two sets\n",
    "    denominator = A.union(B)\n",
    "\n",
    "    # Take the ratio of sizes\n",
    "    similarity = len(nominator)/len(denominator)\n",
    "\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def similarity(groundtruth, pred):\n",
    "    \"\"\"Calculates the normal similarity between two sets.\n",
    "\n",
    "    Args:\n",
    "        A (Set): Set A\n",
    "        B (Set): Set B\n",
    "\n",
    "    Returns:\n",
    "        Integer: 0.00 - 1.00\n",
    "    \"\"\"\n",
    "\n",
    "    # Create sets just in case\n",
    "    groundtruth = set(groundtruth)\n",
    "    pred = set(pred)\n",
    "\n",
    "    # Find intersection of two sets\n",
    "    nominator = groundtruth.intersection(pred)\n",
    "\n",
    "    # Find union of two sets\n",
    "    denominator = groundtruth\n",
    "\n",
    "    # Take the ratio of sizes\n",
    "    similarity = len(nominator)/(len(denominator))\n",
    "\n",
    "    return similarity\n",
    "\n",
    "def resentesize(lst):\n",
    "\n",
    "    sentence = ''\n",
    "\n",
    "    # Loop every 2 items \n",
    "    for item1, item2 in zip(lst[::2], lst[1::2]):\n",
    "        \n",
    "        # Set verb\n",
    "        verb = 'has'\n",
    "        chunk = item2.split(' ')[-1]\n",
    "        if chunk not in nouns or chunk in colors:\n",
    "            verb = 'is'\n",
    "\n",
    "        sentence += f'{item1.capitalize()} {verb} {item2}. '\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "\n",
    "def get_wiki_main_image(title):\n",
    "    url = 'https://en.wikipedia.org/w/api.php'\n",
    "    data = {\n",
    "        'action' :'query',\n",
    "        'format' : 'json',\n",
    "        'formatversion' : 2,\n",
    "        'prop' : 'pageimages|pageterms',\n",
    "        'piprop' : 'original',\n",
    "        'titles' : title\n",
    "    }\n",
    "    response = requests.get(url, data)\n",
    "    json_data = json.loads(response.text)\n",
    "    return json_data['query']['pages'][0]['original']['source'] if len(json_data['query']['pages']) >0 else 'Not found'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retokize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init empty dict for retok\n",
    "species_datalist = collections.defaultdict(list)\n",
    "\n",
    "root = \"../../data/processed/\"\n",
    "file_name = root + 'Triples_Pierre.txt'\n",
    "\n",
    "with open(file_name) as f:\n",
    "   json_data = json.load(f)\n",
    "\n",
    "for idx, (k, lst) in enumerate(json_data.items()):\n",
    "    for l in lst:\n",
    "\n",
    "        # Flatten list of lists\n",
    "        flat_list = [item for sublist in l for item in sublist]\n",
    "        # Retokens some sentence with multiple 'species'\n",
    "        flat_list_multiple_sents = [list(v) for k, v in groupby(flat_list, lambda x: x != 'species') if k]\n",
    "        \n",
    "        for sentence in flat_list_multiple_sents:\n",
    "            # Insert species\n",
    "            sentence.insert(0, 'species')\n",
    "            species_datalist[k].append(sentence)\n",
    "\n",
    "file_name = root + 'Triples_Andrei.txt'\n",
    "\n",
    "with open(file_name) as f:\n",
    "   json_data = json.load(f)\n",
    "\n",
    "for idx, (k, lst) in enumerate(json_data.items()):\n",
    "    for l in lst:\n",
    "\n",
    "        # Flatten list of lists\n",
    "        flat_list = [item for sublist in l for item in sublist]\n",
    "        # Retokens some sentence with multiple 'species'\n",
    "        flat_list_multiple_sents = [list(v) for k, v in groupby(flat_list, lambda x: x != 'species') if k]\n",
    "        \n",
    "        for sentence in flat_list_multiple_sents:\n",
    "            # Insert species\n",
    "            sentence.insert(0, 'species')\n",
    "            species_datalist[k].append(sentence)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_trait_against_DF(trait, df, which_df):\n",
    "    \"\"\"Return the corresponding traits\n",
    "\n",
    "    Args:\n",
    "        trait (string): The trait used\n",
    "        df (DataFrame): The inserted DataFrame\n",
    "        which_df (string): Which of the three DataFrames to use. \n",
    "                           Choices are ['Pierre', 'Andrei', 'Kissling']\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If a DF other then ['Pierre', 'Andrei', 'Kissling']\n",
    "                    is used.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # Error\n",
    "    df_choices = ['Pierre', 'Andrei', 'Kissling']\n",
    "    if which_df not in df_choices:\n",
    "        raise ValueError(f'Choose one of {df_choices}')\n",
    "\n",
    "    column = ''\n",
    "    if which_df == 'Pierre':\n",
    "        if trait == 'Life Form':\n",
    "            column = 'plant type'\n",
    "        elif trait == 'Trunk':\n",
    "            column = 'trunk and root'\n",
    "        elif trait == 'Root':\n",
    "            column = 'trunk and root'\n",
    "        elif trait == 'Stem':\n",
    "            column = 'stem shape'\n",
    "        elif trait == 'Bark Colour':\n",
    "            column = 'bark color'\n",
    "        elif trait == 'Blade Colour':\n",
    "            column = 'blade color'\n",
    "        elif trait == 'Flower Colour':\n",
    "            column = 'flower color'\n",
    "        else:\n",
    "            column = trait.lower()\n",
    "\n",
    "    if which_df == 'Andrei':\n",
    "        if trait == 'Phyllotaxis':\n",
    "            column = ['Leaf position', 'Leaf upper side', 'Leaf lower side']\n",
    "        elif trait == 'Spine':\n",
    "            column = 'Thorns/spines'\n",
    "        elif trait == 'Thornes':\n",
    "            column = 'Thorns/spines'\n",
    "        elif trait == 'Fruit':\n",
    "            column = 'Fruit type'\n",
    "        else:\n",
    "            column = trait.lower()\n",
    "\n",
    "            \n",
    "    \n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_traits = {}\n",
    "\n",
    "for idx, (species, sentences) in enumerate(tqdm(species_datalist.items())):\n",
    "\n",
    "    senteces_matches = collections.defaultdict(list)\n",
    "    \n",
    "    # if idx >= 1:\n",
    "    #     continue\n",
    "\n",
    "    for sentence in sentences:\n",
    "\n",
    "        matches =  set(sentence) & set(traits_list)\n",
    "        matches_color = set(colors) & set(sentence)\n",
    "        if matches and not matches_color:\n",
    "            #print(match, sentence)\n",
    "            for match in matches:\n",
    "\n",
    "                corresponding_traits = corresponding_keys(match.capitalize(), traits_dict)\n",
    "\n",
    "                for corresponding_trait in corresponding_traits:\n",
    "                    senteces_matches[corresponding_trait].append(sentence)\n",
    "\n",
    "                    #print(corresponding_trait, sentence)\n",
    "\n",
    "        elif matches_color and matches:\n",
    "            for match in matches:\n",
    "\n",
    "                corresponding_traits = corresponding_keys(match.capitalize(), traits_dict)\n",
    "                for corresponding_trait in corresponding_traits:\n",
    "                    if 'Colour' in corresponding_trait.split(' '):\n",
    "                        senteces_matches[corresponding_trait].append(sentence)\n",
    "\n",
    "                        #print(\"COLOR\", corresponding_trait, sentence)\n",
    "\n",
    "    species_traits[species] = senteces_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "google_forms_lst = []\n",
    "\n",
    "for idx, species in enumerate(tqdm(species_traits.keys())):\n",
    "\n",
    "    # if idx >= 1:\n",
    "    #     continue\n",
    "\n",
    "    df_name = ''\n",
    "    df_select = [df_Andrei_dummies, df_Pierre]\n",
    "    if species in df_Andrei_dummies.index:\n",
    "        df_name = 'Andrei'\n",
    "        df_select = df_select[0]\n",
    "    elif species in df_Pierre.index:\n",
    "        df_name = 'Pierre'\n",
    "        df_select = df_select[1]\n",
    "    # elif species in df_kissling:\n",
    "    #     df_name = 'Kissling'\n",
    "    #     df_select = df_select[2]\n",
    "    else:\n",
    "        print(species, 'Missing?', df_name)\n",
    "\n",
    "    for trait in species_traits[species]:\n",
    "        \n",
    "        # Init \n",
    "        top_k_list = []\n",
    "        # Match traits\n",
    "        df_trait = match_trait_against_DF(trait, df_select, df_name)\n",
    "\n",
    "        # Get present subtraits\n",
    "        try:\n",
    "            df_subset = df_select[df_select.index == species][df_trait]\n",
    "            present_traits = df_subset.loc[:, df_subset.any()].columns\n",
    "\n",
    "        # Skip traits without GT\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        # Join items\n",
    "        df_sent  = ' '.join(df_trait + present_traits)\n",
    "        # Match against Sentences\n",
    "        for lst in species_traits[species][trait]:\n",
    "            sentence = ' '.join(lst)\n",
    "            j_sim = jaccard_similarity(df_sent, sentence)\n",
    "            # Append to list\n",
    "            top_k_list.append((j_sim, lst))\n",
    "\n",
    "        # Sort list and keep top K\n",
    "        top_k_list.sort(reverse=True)\n",
    "        top_sentences = []\n",
    "\n",
    "        for (_, lst) in top_k_list:\n",
    "            \n",
    "            # Skip duplicated and remove jsim\n",
    "            if lst not in top_sentences:\n",
    "                top_sentences.append(lst)\n",
    "\n",
    "        # Google Forms\n",
    "        #google_forms_lst.append([species, trait, df_trait, present_traits.values])\n",
    "        best_sentences = []\n",
    "\n",
    "        # Extend lists below 5\n",
    "        if len(top_sentences) < k:\n",
    "            empties = [None] * (k - len(top_sentences))\n",
    "            for empty in empties:\n",
    "                top_sentences.append([empty])\n",
    "\n",
    "        for i, top_sentence in enumerate(top_sentences):\n",
    "            if i >= k:\n",
    "                continue\n",
    "            reconstructed_sent = resentesize(top_sentence)\n",
    "            if reconstructed_sent:\n",
    "                best_sentences.append(reconstructed_sent)\n",
    "            else:\n",
    "                best_sentences.append(np.NaN)\n",
    "\n",
    "        #google_forms_lst.append(best_sentences)\n",
    "        google_forms_lst.append((species, trait, df_trait, list(present_traits.values), *best_sentences))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google forms\n",
    "df_google = pd.DataFrame(google_forms_lst, columns=['Species', 'Main Trait', 'GT Main Trait', 'GT Sub Traits', '1', '2', '3', '4', '5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google.to_csv(f'{root}top_sents_all_MainSubTraitsCombi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google_subset = df_google\\\n",
    "                    .dropna()\\\n",
    "                    .sample(n=20, axis=0, random_state=666)\\\n",
    "\n",
    "df_google_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample_species = df_google_subset['Species'].values\n",
    "\n",
    "images_links = {}\n",
    "for species in tqdm(random_sample_species):\n",
    "    species_ = species.replace(' ', '_')\n",
    "    try:\n",
    "        img_url = get_wiki_main_image(species_)\n",
    "        if img_url[-3:] != 'jpg':\n",
    "            img_url = 'https://upload.wikimedia.org/wikipedia/commons/1/14/No_Image_Available.jpg'\n",
    "        # if img_url[-3:].isupper():\n",
    "        #     img_url = 'https://upload.wikimedia.org/wikipedia/commons/1/14/No_Image_Available.jpg'\n",
    "        images_links[species] = img_url\n",
    "    except:\n",
    "        images_links[species] = 'https://upload.wikimedia.org/wikipedia/commons/1/14/No_Image_Available.jpg'\n",
    "\n",
    "# df_google_subset = df_google[df_google['Species'].isin(random_sample_species)]\n",
    "df_google_subset = df_google_subset.set_index('Species')\n",
    "df_google_subset[\"URL\"] = pd.Series(images_links)\n",
    "df_google_subset.to_csv(f'{root}top_sents_all_MainSubTraitsCombi_Random20Subset.csv', sep='\\t')#, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Mar 31 2022, 03:38:35) [Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
