{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "import json\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "from itertools import groupby\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../data/external/\"\n",
    "\n",
    "# Data Pierre\n",
    "file_name = root + 'Dataset_Pierre.csv'\n",
    "df_Pierre = pd.read_csv(file_name, header=[0, 1]) \n",
    "df_Pierre = df_Pierre.iloc[: , 1:]\n",
    "\n",
    "# Data Andrei\n",
    "file_name = root + 'Dataset_Andrei.csv'\n",
    "df_Andrei = pd.read_csv(file_name)\n",
    "\n",
    "# Data Palms\n",
    "file_name = root + 'Dataset_Kissling.txt'\n",
    "df_Daniel = pd.read_csv(file_name,\n",
    "                 sep='\\t', encoding='Latin-1')\n",
    "palm_species = df_Daniel[~df_Daniel.isnull().any(axis=1)]['SpecName'].values\n",
    "df_Daniel.set_index('SpecName', inplace=True)\n",
    "\n",
    "# # Values Pierre\n",
    "# print('Pierre')\n",
    "# print(df_Pierre.columns.get_level_values(0).unique())\n",
    "\n",
    "# # Values df_Andrei\n",
    "# print('Andrei')\n",
    "# print(df_Andrei.columns.unique())\n",
    "\n",
    "# # Values df_Andrei\n",
    "# print('Daniel')\n",
    "# print(df_Daniel.columns.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = list(stopwords.words('english'))\n",
    "sw.append('like')\n",
    "sw.append('color')\n",
    "sw.append('colour')\n",
    "sw.append('a')\n",
    "sw.append('x')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = list(stopwords.words('english'))\n",
    "sw.append('like')\n",
    "sw.append('color')\n",
    "sw.append('colour')\n",
    "sw.append('a')\n",
    "sw.append('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(A, B):\n",
    "    \"\"\"Calculates the Jaccard similarity two sets.\n",
    "\n",
    "    Args:\n",
    "        A (Set): Set A\n",
    "        B (Set): Set B\n",
    "\n",
    "    Returns:\n",
    "        Integer: 0.00 - 1.00\n",
    "    \"\"\"\n",
    "\n",
    "    # Create sets just in case\n",
    "    A = set(A)\n",
    "    B = set(B)\n",
    "    \n",
    "    # Get intersection of two sets\n",
    "    nominator = A.intersection(B)\n",
    "\n",
    "    # Find union of two sets\n",
    "    denominator = A.union(B)\n",
    "\n",
    "    # Take the ratio of sizes\n",
    "    similarity = len(nominator)/len(denominator)\n",
    "\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def similarity(groundtruth, pred):\n",
    "    \"\"\"Calculates the normal similarity between two sets.\n",
    "\n",
    "    Args:\n",
    "        A (Set): Set A\n",
    "        B (Set): Set B\n",
    "\n",
    "    Returns:\n",
    "        Integer: 0.00 - 1.00\n",
    "    \"\"\"\n",
    "\n",
    "    # Create sets just in case\n",
    "    groundtruth = set(groundtruth)\n",
    "    pred = set(pred)\n",
    "\n",
    "    # Find intersection of two sets\n",
    "    nominator = groundtruth.intersection(pred)\n",
    "\n",
    "    # Find union of two sets\n",
    "    denominator = groundtruth\n",
    "\n",
    "    # Take the ratio of sizes\n",
    "    similarity = len(nominator)/(len(denominator))\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Pierre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../data/processed/\"\n",
    "file_name = root + 'Triples_Pierre.txt'\n",
    "\n",
    "with open(file_name) as f:\n",
    "   data = json.load(f)\n",
    "\n",
    "# species = list(data.keys())\n",
    "species = df_Pierre.xs('species', level=1, axis=1)['Species'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_traits_Pierre = [\n",
    "    ('plant type', 'type'), \n",
    "    ('phyllotaxis'),\n",
    "    ('trunk, root'), \n",
    "    ('latex'),\n",
    "    ('crown'),\n",
    "    ('stem shape', 'stem'), \n",
    "    ('bark'), \n",
    "    ('bark color', 'bark colour'), \n",
    "    ('leaf shape', 'shape', 'leaf'), \n",
    "    ('petiole'),\n",
    "    ('leaf blade', 'blade'), \n",
    "    ('leaf margin', 'margin'), \n",
    "    ('leaf base', 'base'), \n",
    "    ('leaf apex', 'apex'), \n",
    "    ('vein'),\n",
    "    ('tendril'), \n",
    "    ('spine'), \n",
    "    ('blade color', 'blade'), \n",
    "    ('fruit'), \n",
    "    ('XXX'), \n",
    "    ('inflorescences'),\n",
    "    ('sexuality', 'sex'), \n",
    "    ('flower color', 'flower', 'flower colour', 'color', 'colour'), \n",
    "    ('flower shape', 'flower', 'shape')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Traits \n",
    "traits_main_Pierre = df_Pierre.columns.get_level_values(0).unique()[1:]\n",
    "\n",
    "# Init dict\n",
    "traits_dict_Pierre = {}\n",
    "\n",
    "# Extract sub traits per main trait\n",
    "for main_trait in traits_main_Pierre:\n",
    "\n",
    "    # Slice dataframe\n",
    "    sub_traits = list(df_Pierre.xs(main_trait, axis=1).columns)\n",
    "    sub_traits = [item.lower().split() for item in sub_traits]\n",
    "    sub_traits = list(set([item for sublist in sub_traits for item in sublist if item not in sw]))\n",
    "    \n",
    "    # # Split main traits\n",
    "    main_traits_split =  main_trait.split()\n",
    "    main_traits_split.insert(0, main_trait)\n",
    "\n",
    "    # Add to dict\n",
    "    traits_dict_Pierre[tuple(set(main_traits_split))] = sub_traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [00:19<00:00, 18.76it/s]\n"
     ]
    }
   ],
   "source": [
    "candidate_list_pierre = []\n",
    "top_k = 3\n",
    "\n",
    "for species_ID, spss in enumerate(tqdm(species[0:])):\n",
    "\n",
    "    # Missing 1 species?\n",
    "    try:\n",
    "\n",
    "        for main_trait, main_trait_orig in zip(traits_dict_Pierre.keys(), traits_main_Pierre):\n",
    "        # for main_trait in main_traits_Pierre:    \n",
    "            \n",
    "            # Init variables\n",
    "            matches_main_traits = []\n",
    "            matches_sub_traits = []\n",
    "\n",
    "            # Get present subtraits\n",
    "            indices = df_Pierre[main_trait_orig].iloc[species_ID].values\n",
    "            traits = list(df_Pierre.xs(main_trait_orig, axis=1).columns)\n",
    "            sub_traits = [t.lower() for i, t in zip(indices, traits) if i == 1]\n",
    "            sub_traits_flat = [item for sublist in sub_traits for item in sublist.split(' ')]\n",
    "\n",
    "            for idx, lst in enumerate(data[spss]):\n",
    "\n",
    "                # Flatten list of lists\n",
    "                flat_list = [item for sublist in lst for item in sublist]\n",
    "                # Retokens some sentence with multiple 'species'\n",
    "                flat_list_multiple_sents = [list(v) for k, v in groupby(flat_list, lambda x: x != 'species') if k]\n",
    "                \n",
    "                for sentence in flat_list_multiple_sents:\n",
    "                \n",
    "                    # Insert species\n",
    "                    sentence.insert(0, 'species')\n",
    "\n",
    "                    # Match the main traits\n",
    "                    main_trait_match = set(main_trait) & set(sentence)\n",
    "                    gt = set(main_trait_match)\n",
    "                    pred = set(sentence)\n",
    "                    j_sim = jaccard_similarity(gt, pred)\n",
    "\n",
    "                    if j_sim:\n",
    "                        #print(main_trait, main_trait_match, sentence)\n",
    "                        matches_main_traits.append((j_sim, sentence))\n",
    "\n",
    "                        # Match the main traits\n",
    "                        sub_trait_match = set(sub_traits_flat) & set(sentence)\n",
    "                        gt = set(sub_trait_match)\n",
    "                        pred = set(sentence)\n",
    "                        j_sim = jaccard_similarity(gt, pred)\n",
    "\n",
    "                        if j_sim:\n",
    "                            matches_sub_traits.append((j_sim, sentence))\n",
    "\n",
    "                        else:\n",
    "                            matches_sub_traits.append((0, []))\n",
    "\n",
    "                    else:\n",
    "                        matches_main_traits.append((0, []))\n",
    "                        matches_sub_traits.append((0, []))\n",
    "\n",
    "            matches_main_traits.sort(reverse=True)\n",
    "            matches_sub_traits.sort(reverse=True)\n",
    "            for k, mmt in enumerate(matches_main_traits[0:top_k]):\n",
    "                # print(main_trait, mmt)\n",
    "                candidate_list_pierre.append((spss, main_trait, 'Main', k + 1, mmt[1]))\n",
    "            for k, mmt in enumerate(matches_sub_traits[0:top_k]):\n",
    "                # print(sub_traits, mmt)\n",
    "                candidate_list_pierre.append((spss, sub_traits, 'Sub', k + 1, mmt[1]))\n",
    "    # Missing 1 species?\n",
    "    except:\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Traits</th>\n",
       "      <th>Trait Type</th>\n",
       "      <th>Top K</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acacia amythethophylla</td>\n",
       "      <td>(type, plant type, plant)</td>\n",
       "      <td>Main</td>\n",
       "      <td>1</td>\n",
       "      <td>[species, plants, plants, plant, plant, useful]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acacia amythethophylla</td>\n",
       "      <td>(type, plant type, plant)</td>\n",
       "      <td>Main</td>\n",
       "      <td>2</td>\n",
       "      <td>[species, plant, plant, use, use, plant use]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acacia amythethophylla</td>\n",
       "      <td>(type, plant type, plant)</td>\n",
       "      <td>Main</td>\n",
       "      <td>3</td>\n",
       "      <td>[species, plant, plant, sugar, sugar, plant su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acacia amythethophylla</td>\n",
       "      <td>[tree, shrub]</td>\n",
       "      <td>Sub</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acacia amythethophylla</td>\n",
       "      <td>[tree, shrub]</td>\n",
       "      <td>Sub</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51835</th>\n",
       "      <td>Ziziphus spina-christi</td>\n",
       "      <td>(shape, flower shape, flower)</td>\n",
       "      <td>Main</td>\n",
       "      <td>2</td>\n",
       "      <td>[species, leaf, leaf, shape, shape, leaf shape]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51836</th>\n",
       "      <td>Ziziphus spina-christi</td>\n",
       "      <td>(shape, flower shape, flower)</td>\n",
       "      <td>Main</td>\n",
       "      <td>3</td>\n",
       "      <td>[species, flowers, flowers, flower, flower of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51837</th>\n",
       "      <td>Ziziphus spina-christi</td>\n",
       "      <td>[five-petalled flower]</td>\n",
       "      <td>Sub</td>\n",
       "      <td>1</td>\n",
       "      <td>[species, plant, plant, plant, plant, flower]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51838</th>\n",
       "      <td>Ziziphus spina-christi</td>\n",
       "      <td>[five-petalled flower]</td>\n",
       "      <td>Sub</td>\n",
       "      <td>2</td>\n",
       "      <td>[species, flowers, flowers, flower, flower of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51839</th>\n",
       "      <td>Ziziphus spina-christi</td>\n",
       "      <td>[five-petalled flower]</td>\n",
       "      <td>Sub</td>\n",
       "      <td>3</td>\n",
       "      <td>[species, flowers, flowers, flower, flower of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51840 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Species                         Traits Trait Type  \\\n",
       "0      Acacia amythethophylla      (type, plant type, plant)       Main   \n",
       "1      Acacia amythethophylla      (type, plant type, plant)       Main   \n",
       "2      Acacia amythethophylla      (type, plant type, plant)       Main   \n",
       "3      Acacia amythethophylla                  [tree, shrub]        Sub   \n",
       "4      Acacia amythethophylla                  [tree, shrub]        Sub   \n",
       "...                       ...                            ...        ...   \n",
       "51835  Ziziphus spina-christi  (shape, flower shape, flower)       Main   \n",
       "51836  Ziziphus spina-christi  (shape, flower shape, flower)       Main   \n",
       "51837  Ziziphus spina-christi         [five-petalled flower]        Sub   \n",
       "51838  Ziziphus spina-christi         [five-petalled flower]        Sub   \n",
       "51839  Ziziphus spina-christi         [five-petalled flower]        Sub   \n",
       "\n",
       "       Top K                                           Sentence  \n",
       "0          1    [species, plants, plants, plant, plant, useful]  \n",
       "1          2       [species, plant, plant, use, use, plant use]  \n",
       "2          3  [species, plant, plant, sugar, sugar, plant su...  \n",
       "3          1                                                 []  \n",
       "4          2                                                 []  \n",
       "...      ...                                                ...  \n",
       "51835      2    [species, leaf, leaf, shape, shape, leaf shape]  \n",
       "51836      3  [species, flowers, flowers, flower, flower of ...  \n",
       "51837      1      [species, plant, plant, plant, plant, flower]  \n",
       "51838      2  [species, flowers, flowers, flower, flower of ...  \n",
       "51839      3  [species, flowers, flowers, flower, flower of ...  \n",
       "\n",
       "[51840 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Pierre_traits = pd.DataFrame(candidate_list_pierre, columns=['Species', 'Traits', 'Trait Type', 'Top K', 'Sentence'])\n",
    "df_Pierre_traits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Andrei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open triples\n",
    "root = \"../data/processed/\"\n",
    "file_name = root + 'Triples_Andrei.txt'\n",
    "\n",
    "with open(file_name) as f:\n",
    "   json_data = json.load(f)\n",
    "\n",
    "# Get species\n",
    "species = list(json_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dummies to match DF Pierre\n",
    "df_Andrei_dummies = pd.get_dummies(df_Andrei.iloc[:, 2:])\n",
    "# Set species back\n",
    "df_Andrei_dummies = df_Andrei_dummies.set_index(df_Andrei['Species'])\n",
    "\n",
    "# Create tuple list for multi index\n",
    "Andrei_multi_index = []\n",
    "for top_index in df_Andrei.columns:\n",
    "    for sub_index in df_Andrei_dummies.columns:\n",
    "        if top_index in sub_index:\n",
    "\n",
    "            sub_index = sub_index.split('_')[-1]\n",
    "            Andrei_multi_index.append((top_index, sub_index))\n",
    "\n",
    "# Set Mutli index\n",
    "df_Andrei_dummies.columns = pd.MultiIndex.from_tuples(Andrei_multi_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Traits \n",
    "traits_main_Andrei = df_Andrei.columns.get_level_values(0).unique()[2:]\n",
    "\n",
    "# Init dict\n",
    "traits_dict_Andrei = {}\n",
    "\n",
    "# Extract sub traits per main trait\n",
    "for main_trait in traits_main_Andrei:\n",
    "\n",
    "    # Slice dataframe\n",
    "    sub_traits = list(df_Andrei_dummies.xs(main_trait, axis=1).columns)\n",
    "    sub_traits = [item.lower().split() for item in sub_traits]\n",
    "    sub_traits = list(set([item for sublist in sub_traits for item in sublist if item not in sw]))\n",
    "    \n",
    "    # Split main traits\n",
    "    for main_traits_split in main_trait.split():\n",
    "\n",
    "        # Remove main from sub\n",
    "        sub_traits = list(set(sub_traits) - set([main_traits_split]))\n",
    "        # Append traits to dict\n",
    "        traits_dict_Andrei[main_traits_split] = sub_traits\n",
    "        \n",
    "    # Original main trais (Just in case)\n",
    "    traits_dict_Andrei[main_trait] = sub_traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Andrei_dummies['Life form'].iloc[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:01, 32.52it/s]\n"
     ]
    }
   ],
   "source": [
    "candidate_list_Andrei = []\n",
    "top_k = 3\n",
    "\n",
    "for species_ID, spss in tqdm(enumerate(species[0:])):\n",
    " \n",
    "    for main_trait, main_trait_orig in zip(traits_dict_Andrei.keys(), traits_main_Andrei):\n",
    "    # for main_trait in main_traits_Pierre:    \n",
    "        \n",
    "        # Init variables\n",
    "        matches_main_traits = []\n",
    "        matches_sub_traits = []\n",
    "\n",
    "        # Get present subtraits\n",
    "        indices = df_Andrei_dummies[main_trait_orig].iloc[species_ID].values\n",
    "        traits = list(df_Andrei_dummies.xs(main_trait_orig, axis=1).columns)\n",
    "        sub_traits = [t.lower() for i, t in zip(indices, traits) if i == 1]\n",
    "        sub_traits_flat = [item for sublist in sub_traits for item in sublist.split(' ')]\n",
    "\n",
    "        for idx, lst in enumerate(json_data[spss]):\n",
    "\n",
    "            # Flatten list of lists\n",
    "            flat_list = [item for sublist in lst for item in sublist]\n",
    "            # Retokens some sentence with multiple 'species'\n",
    "            flat_list_multiple_sents = [list(v) for k, v in groupby(flat_list, lambda x: x != 'species') if k]\n",
    "            \n",
    "            for sentence in flat_list_multiple_sents:\n",
    "            \n",
    "                # Insert species\n",
    "                sentence.insert(0, 'species')\n",
    "\n",
    "                # Match the main traits\n",
    "                main_trait_match = set(main_trait) & set(sentence)\n",
    "                gt = set(main_trait_match)\n",
    "                pred = set(sentence)\n",
    "                j_sim = jaccard_similarity(gt, pred)\n",
    "\n",
    "                if j_sim:\n",
    "                    #print(main_trait, main_trait_match, sentence)\n",
    "                    matches_main_traits.append((j_sim, sentence))\n",
    "\n",
    "                    # Match the main traits\n",
    "                    sub_trait_match = set(sub_traits_flat) & set(sentence)\n",
    "                    gt = set(sub_trait_match)\n",
    "                    pred = set(sentence)\n",
    "                    j_sim = jaccard_similarity(gt, pred)\n",
    "\n",
    "                    if j_sim:\n",
    "                        matches_sub_traits.append((j_sim, sentence))\n",
    "\n",
    "                    else:\n",
    "                        matches_sub_traits.append((0, []))\n",
    "\n",
    "                else:\n",
    "                    matches_main_traits.append((0, []))\n",
    "                    matches_sub_traits.append((0, []))\n",
    "\n",
    "        matches_main_traits.sort(reverse=True)\n",
    "        matches_sub_traits.sort(reverse=True)\n",
    "        for k, mmt in enumerate(matches_main_traits[0:top_k]):\n",
    "            # print(main_trait, mmt)\n",
    "            candidate_list_Andrei.append((spss, main_trait, 'Main', k + 1, mmt[1]))\n",
    "        for k, mmt in enumerate(matches_sub_traits[0:top_k]):\n",
    "            # print(sub_traits, mmt)\n",
    "            candidate_list_Andrei.append((spss, sub_traits, 'Sub', k + 1, mmt[1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Traits</th>\n",
       "      <th>Trait Type</th>\n",
       "      <th>Top K</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avicennia germinans</td>\n",
       "      <td>Life</td>\n",
       "      <td>Main</td>\n",
       "      <td>1</td>\n",
       "      <td>[species, capsule, capsule, capsule, capsule, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avicennia germinans</td>\n",
       "      <td>Life</td>\n",
       "      <td>Main</td>\n",
       "      <td>2</td>\n",
       "      <td>[species, fruit, fruit, fruit, fruit, capsule,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avicennia germinans</td>\n",
       "      <td>Life</td>\n",
       "      <td>Main</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avicennia germinans</td>\n",
       "      <td>[tree]</td>\n",
       "      <td>Sub</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avicennia germinans</td>\n",
       "      <td>[tree]</td>\n",
       "      <td>Sub</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>Guaiacum sanctum</td>\n",
       "      <td>Inflorescence</td>\n",
       "      <td>Main</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>Guaiacum sanctum</td>\n",
       "      <td>Inflorescence</td>\n",
       "      <td>Main</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>Guaiacum sanctum</td>\n",
       "      <td>[brown]</td>\n",
       "      <td>Sub</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>Guaiacum sanctum</td>\n",
       "      <td>[brown]</td>\n",
       "      <td>Sub</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>Guaiacum sanctum</td>\n",
       "      <td>[brown]</td>\n",
       "      <td>Sub</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Species         Traits Trait Type  Top K  \\\n",
       "0     Avicennia germinans           Life       Main      1   \n",
       "1     Avicennia germinans           Life       Main      2   \n",
       "2     Avicennia germinans           Life       Main      3   \n",
       "3     Avicennia germinans         [tree]        Sub      1   \n",
       "4     Avicennia germinans         [tree]        Sub      2   \n",
       "...                   ...            ...        ...    ...   \n",
       "5995     Guaiacum sanctum  Inflorescence       Main      2   \n",
       "5996     Guaiacum sanctum  Inflorescence       Main      3   \n",
       "5997     Guaiacum sanctum        [brown]        Sub      1   \n",
       "5998     Guaiacum sanctum        [brown]        Sub      2   \n",
       "5999     Guaiacum sanctum        [brown]        Sub      3   \n",
       "\n",
       "                                               Sentence  \n",
       "0     [species, capsule, capsule, capsule, capsule, ...  \n",
       "1     [species, fruit, fruit, fruit, fruit, capsule,...  \n",
       "2                                                    []  \n",
       "3                                                    []  \n",
       "4                                                    []  \n",
       "...                                                 ...  \n",
       "5995                                                 []  \n",
       "5996                                                 []  \n",
       "5997                                                 []  \n",
       "5998                                                 []  \n",
       "5999                                                 []  \n",
       "\n",
       "[6000 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Andrei_traits = pd.DataFrame(candidate_list_Andrei, columns=['Species', 'Traits', 'Trait Type', 'Top K', 'Sentence'])\n",
    "df_Andrei_traits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Kissling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knowledge_graph_subset(species, parts, kn_cleaned):\n",
    "\n",
    "    # Init variables\n",
    "    baseparts, traits, source, relation, target, correct_parts = ([] for i in range(6))\n",
    "\n",
    "    # Extract the data\n",
    "    for (sub, rel, obj) in kn_cleaned:\n",
    "        #print((sub, rel, obj))\n",
    "        if sub == 'species':\n",
    "            sub = species\n",
    "        source.append(sub), relation.append(rel), target.append(obj), \n",
    "        if rel == 'has_main_part':\n",
    "            baseparts.append(obj)\n",
    "        if rel == 'has_sub_part':\n",
    "            traits.append(obj)\n",
    "\n",
    "    # Fit data into DF\n",
    "    kg_df = pd.DataFrame({'source':source, 'target':target, 'edge':relation})\n",
    "    if parts:\n",
    "        if type(parts) != list:\n",
    "            parts = [parts]\n",
    "        relations = [f'{part.lower()} temp' for part in parts]\n",
    "        #relations += ['has_main_part', 'has_sub_part']\n",
    "    \n",
    "    values = list(kg_df[kg_df['edge'].isin(relations)]['source'].values)\n",
    "    values += list(kg_df[kg_df['edge'].isin(relations)]['target'].values) \n",
    "    \n",
    "    return list(set(values))\n",
    "\n",
    "def possible_parts(species, data):\n",
    "    return [obj for (sub, rel, obj) in data[species] if rel=='has_main_part']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open triples\n",
    "root = \"../data/processed/\"\n",
    "file_name = root + 'Triples_Kissling.pkl'\n",
    "data = pickle.load(open(file_name, 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_dict = {\n",
    "    'stem':\n",
    "    ['stem', 'trunk', 'plant',],\n",
    "    'leaf':\n",
    "    ['leaf', 'leaflet', 'leaves'],\n",
    "    'fruit':\n",
    "    ['fruit'],\n",
    "    'petiole':\n",
    "    ['petiole'],\n",
    "    'branch':\n",
    "    ['branch']\n",
    "            }\n",
    "\n",
    "fruitshapes = list(df_Daniel['FruitShape'].unique())\n",
    "fruitshapes += ['fusiform']\n",
    "\n",
    "colors = []\n",
    "for row in df_Daniel['MainFruitColors']:\n",
    "    try:\n",
    "        for color in row.split(';'):\n",
    "            colors.append(color.strip())\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "\n",
    "colors = list(set(colors))\n",
    "\n",
    "multi_index_part = [\n",
    "     'name', 'name', 'name', 'name',\n",
    "     'stem', 'stem', 'stem', 'stem', 'stem',\n",
    "     'leaf', \n",
    "     'stem', 'stem', 'stem',\n",
    "     'leaf', 'leaf', 'branch',\n",
    "     'petiole', \n",
    "     'fruit', 'fruit', 'fruit', 'fruit', 'fruit', 'fruit', 'fruit', 'fruit', 'fruit', 'fruit', 'fruit', \n",
    "]\n",
    "\n",
    "multi_index_binary = [\n",
    "     'no', 'no', 'no', 'no',\n",
    "     'yes', 'yes', 'yes', 'yes', 'yes',\n",
    "     'yes', \n",
    "     'no', 'no', 'no',\n",
    "     'no', 'no', 'no',\n",
    "     'no', \n",
    "     'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', \n",
    "]\n",
    "\n",
    "multi_index_int  = [\n",
    "     'no', 'no', 'no', 'no',\n",
    "     'yes', 'yes', 'yes', 'yes', 'yes',\n",
    "     'yes', \n",
    "     'yes', 'yes', 'no',\n",
    "     'yes', 'yes', 'yes',\n",
    "     'yes', \n",
    "     'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', \n",
    "]\n",
    "\n",
    "df_Daniel.columns = pd.MultiIndex.from_arrays([df_Daniel.columns, multi_index_part, multi_index_binary, multi_index_int])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mimick the original DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palm_information_dict = collections.defaultdict(list)\n",
    "\n",
    "\n",
    "for palm in tqdm(list(data.keys())[0:]):\n",
    "    for part in list(part_dict.keys())[0:]:\n",
    "\n",
    "        # Get palm subset\n",
    "        # Part\n",
    "        df_part = df_Daniel.xs(part, axis=1, level=1)\n",
    "        if part == 'stem':\n",
    "            # Binary?\n",
    "            df_part_binary = df_part.xs('yes', axis=1, level=1)\n",
    "            series_binaries = df_part_binary.loc[palm]\n",
    "        # Binary?\n",
    "        df_part_nonbinary = df_part.xs('no', axis=1, level=1)\n",
    "        if part == 'fruit':\n",
    "            df_part_nonbinary_strings = df_part_nonbinary.xs('no', axis=1, level=1)\n",
    "            series_strings = df_part_nonbinary_strings.loc[palm]\n",
    "            \n",
    "            #print(series_strings)\n",
    "        # Integer?\n",
    "        df_part_nonbinary_integers = df_part_nonbinary.xs('yes', axis=1, level=1)\n",
    "        # Palmseries\n",
    "        series_integers = df_part_nonbinary_integers.loc[palm]\n",
    "        \n",
    "        # Get kn subset\n",
    "        graph_array = knowledge_graph_subset(palm, part_dict[part], data[palm])\n",
    "        if part == 'stem':\n",
    "            for (name, _), elem in series_binaries.iteritems():\n",
    "                name = re.sub(r'Stem', '', name)\n",
    "                name = name.lower()\n",
    "                if name in graph_array:\n",
    "                    palm_information_dict[palm].append(1)\n",
    "                    #print(f'{name} == {elem} == {1.0}')\n",
    "                else:\n",
    "                    palm_information_dict[palm].append(0)\n",
    "                    #print(f'{name} == {elem} == {0.0}')\n",
    "                    \n",
    "        if part == 'fruit':\n",
    "            #print(series_strings)\n",
    "            for name, elem in series_strings.iteritems():\n",
    "                if name == 'FruitSizeCategorical':\n",
    "                    #print(f'{name} SKIPPED')\n",
    "                    continue\n",
    "                elif name == 'FruitShape':\n",
    "                    shape = list(set(fruitshapes) & set(graph_array))\n",
    "                    if shape:\n",
    "                        palm_information_dict[palm].append(shape[0])\n",
    "                        #print(f'{name} == {elem} ==  {shape[0]}')\n",
    "                    else:\n",
    "                        palm_information_dict[palm].append(np.NaN)\n",
    "                        #print(f'{name} == {elem} == NaN')\n",
    "                elif name == 'FruitColorDescription':\n",
    "                    #print(f'{name} SKIPPED')\n",
    "                    continue\n",
    "                elif name == 'MainFruitColors':\n",
    "                    #colors = [c.strip() for c in elem.split(';')]\n",
    "                    found_colors = list(set(colors) & set(graph_array))\n",
    "                    palm_information_dict[palm].append(found_colors)\n",
    "                    #print(f'{name} == {colors} ==  {found_colors}')\n",
    "                elif name == 'Conspicuousness':\n",
    "                    #print(f'{name} SKIPPED')\n",
    "                    continue\n",
    "            \n",
    "        graph_ints = []\n",
    "        # Get the ints\n",
    "        for elem in graph_array:\n",
    "            try:\n",
    "                graph_ints.append(float(elem))\n",
    "            except:\n",
    "                continue\n",
    "        #print(graph_ints)\n",
    "        for name, elem in series_integers.iteritems():\n",
    "            if type(elem) != str:\n",
    "                try:\n",
    "                    closest = min(graph_ints, key=lambda x:abs(x - elem))\n",
    "                except:\n",
    "                    closest = np.NaN\n",
    "                palm_information_dict[palm].append(closest)\n",
    "                #print(f'{name} == {elem} == {closest}')\n",
    "\n",
    "# Rename the columns\n",
    "df_Daniel_own = pd.DataFrame.from_dict(palm_information_dict, orient='index')\n",
    "df_Daniel_own.columns = [\n",
    "    'Climbing', 'Acaulescent', 'Erect', 'StemSolitary', 'StemArmed',\n",
    "    'MaxStemHeight_m', 'MaxStemDia_cm', 'MaxLeafNumber', 'Max_Blade_Length_m',\n",
    "    'FruitShape', 'MainFruitColors', \n",
    "    'AverageFruitLength_cm', 'MinFruitLength_cm', 'MaxFruitLength_cm',\n",
    "    'AverageFruitWidth_cm', 'MinFruitWidth_cm', 'MaxFruitWidth_cm',\n",
    "    'Max_Petiole_length_m',\n",
    "    'Max_Rachis_Length_m',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Daniel_own"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../data/processed/\"\n",
    "df_Andrei_own.to_csv(f'{folder}top_sents_Andrei.csv')\n",
    "df_Pierre_traits.to_csv(f'{folder}top_sents_Pierre.csv')\n",
    "# df_Daniel_own.to_csv(f'{folder}top_sents_Andrei.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
